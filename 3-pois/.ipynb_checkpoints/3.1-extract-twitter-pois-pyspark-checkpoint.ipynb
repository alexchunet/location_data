{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import socket\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, from_json\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import MapType, StringType, IntegerType, StructType, StructField, FloatType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Time:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(0, 3526, 38000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Running Time:')\n",
    "datetime.fromtimestamp(1564019038783/1000) - datetime.fromtimestamp(1564015512745/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    if 'samuel' in socket.gethostname().lower():\n",
    "        print('Create Local SparkSession')\n",
    "        spark = SparkSession.builder.config(\n",
    "        \"spark.driver.host\", \"localhost\").appName(\n",
    "        \"extract-data-from-geolocated-tweets\").getOrCreate()\n",
    "    else:\n",
    "        print('Create Cluster SparkSession')\n",
    "        spark = SparkSession.builder.appName(\n",
    "        \"extract-data-from-geolocated-tweets\").getOrCreate()\n",
    "    \n",
    "# Local\n",
    "print('Hostname:', socket.gethostname())\n",
    "if  'samuel' in socket.gethostname().lower():\n",
    "    path_to_tweets  = '../../data/tweets/tweets-with-geocoordinates-or-place/'\n",
    "    path_to_locations = '../data/locations/'\n",
    "# Cluster\n",
    "else:\n",
    "    path_to_tweets   = '/user/spf248/twitter/parsed/tweets/tweets-with-geocoordinates-or-place/'\n",
    "    path_to_locations = '/user/spf248/twitter/data/locations/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Import:')\n",
    "start = timer()\n",
    "\n",
    "df = spark.read.option(\n",
    "'compression', 'bzip2').option(\n",
    "\"multiLine\", \"true\").option(\n",
    "\"encoding\", \"UTF-8\").option(\n",
    "\"mode\", \"FAILFAST\").json(\n",
    "path_to_tweets+'tweets-with-geocoordinates-or-place-from-decahose-partition-9-block-95.json.bz2')\n",
    "\n",
    "schema = df.schema\n",
    "\n",
    "# Getting Error Without Allowing For Multiline\n",
    "df = spark.read.option(\n",
    "'compression', 'bzip2').option(\n",
    "\"multiLine\", \"true\").option(\n",
    "\"encoding\", \"UTF-8\").option(\n",
    "\"mode\", \"FAILFAST\").schema(schema).json(\n",
    "path_to_tweets+'tweets-with-geocoordinates-or-place-from-decahose-partition-*-block-*.json.bz2')\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Repartition')\n",
    "tweets = tweets.repartition(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(schema, prefix=None):\n",
    "    fields = []\n",
    "    for field in schema.fields:\n",
    "        name = prefix + '.' + field.name if prefix else field.name\n",
    "        dtype = field.dataType\n",
    "        if isinstance(dtype, ArrayType):\n",
    "            dtype = dtype.elementType\n",
    "\n",
    "        if isinstance(dtype, StructType):\n",
    "            fields += flatten(dtype, prefix=name)\n",
    "        else:\n",
    "            fields.append(name)\n",
    "\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.select('place')\n",
    "\n",
    "# Drop Place Values That Are Null\n",
    "tweets = tweets.where(col(\"place\").isNotNull())\n",
    "\n",
    "# Flatten Nested Structure\n",
    "tweets = tweets.select(flatten(tweets.schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- coordinates: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- full_name: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- place_type: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n",
      "Schema: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Schema:\", tweets.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUPBY ID\n"
     ]
    }
   ],
   "source": [
    "print('GROUPBY ID')\n",
    "\n",
    "tweets = tweets.groupBy(tweets['id']).agg(\n",
    "F.first(tweets['coordinates']).alias('coordinates'), \n",
    "F.first(tweets['type']).alias('type'),\n",
    "F.first(tweets['country']).alias('country'),\n",
    "F.first(tweets['country_code']).alias('country_code'),\n",
    "F.first(tweets['full_name']).alias('full_name'),\n",
    "F.first(tweets['name']).alias('name'),\n",
    "F.first(tweets['place_type']).alias('place_type'),\n",
    "F.first(tweets['url']).alias('url'),\n",
    "F.count(tweets['id']).alias('n_obs'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save\n",
      "Computing Time: 10 sec\n"
     ]
    }
   ],
   "source": [
    "print('Save')\n",
    "start = timer()\n",
    "\n",
    "tweets.write.mode(\"overwrite\").parquet(path_to_locations+'pois')\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
